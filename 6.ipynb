{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pyproj import Geod\nimport datetime\nfrom matplotlib import pyplot as plt\nimport seaborn as snss\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv( \"../input/train.csv\" )\ntest_data = pd.read_csv( \"../input/test.csv\" )","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Utiliy functions\n\n#Get distance between pairs of lat-lon points\nwgs84_geod = Geod(ellps='WGS84')\ndef get_distance(lat1,lon1,lat2,lon2):\n    az12,az21,dist = wgs84_geod.inv(lon1,lat1,lon2,lat2)\n    return dist\n\n# Convert time object to seconds\ndef to_seconds(time):\n    return (time.hour * 60 + time.minute) * 60 + time.second","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(data):\n    return ((data - data.min()) / (data.max() - data.min()))\n\ndef process_data(data):\n    # Calculating distance (km) based on longitude/latituides and adding it in a new column 'dist'\n    data['dist'] = get_distance(data['pickup_latitude'].tolist(), data['pickup_longitude'].tolist(),\n                                data['dropoff_latitude'].tolist(), data['dropoff_longitude'].tolist())\n    \n    data['dist'] = data['dist'] / 1000\n    \n    # Replacing N of store_and_fwd_flag with 0 and Y with 1\n    data = data.replace({'N': 0, 'Y': 1})\n\n    data['pickup_datetime'] = pd.to_datetime(data['pickup_datetime'])    \n    data['pickup_weekday'] = data.pickup_datetime.dt.weekday\n    data['pickup_month'] = data.pickup_datetime.dt.month\n    data['pickup_hour'] = data.pickup_datetime.dt.hour\n    data['pickup_min'] = data.pickup_datetime.dt.minute\n    data['pickup_second'] = data.pickup_datetime.dt.second\n    data['is_weekend'] = data.pickup_weekday.map(lambda x: 1 if x >= 5 else 0)\n    \n    # Dropping columns no longer required\n    data = data.drop(['pickup_latitude','pickup_longitude', 'pickup_datetime',\n                      'dropoff_latitude','dropoff_longitude', 'id'], axis=1)\n     \n    return data","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_data(TRAIN_DIR, TEST_DIR, nrows=None):\n    data_train = pd.read_csv(TRAIN_DIR,\n                             parse_dates=[\"pickup_datetime\",\n                                          \"dropoff_datetime\"],\n                             nrows=nrows)\n    data_test = pd.read_csv(TEST_DIR,\n                            parse_dates=[\"pickup_datetime\"],\n                            nrows=nrows)\n    data_train = data_train.drop(['dropoff_datetime'], axis=1)\n    data_train.loc[:, 'store_and_fwd_flag'] = data_train['store_and_fwd_flag'].map({'Y': True,\n                                                                                    'N': False})\n    data_test.loc[:, 'store_and_fwd_flag'] = data_test['store_and_fwd_flag'].map({'Y': True,\n                                                                                  'N': False})\n    data_train = data_train[data_train.trip_duration < data_train.trip_duration.quantile(0.99)]\n\n    xlim = [-74.03, -73.77]\n    ylim = [40.63, 40.85]\n    data_train = data_train[(data_train.pickup_longitude> xlim[0]) & (data_train.pickup_longitude < xlim[1])]\n    data_train = data_train[(data_train.dropoff_longitude> xlim[0]) & (data_train.dropoff_longitude < xlim[1])]\n    data_train = data_train[(data_train.pickup_latitude> ylim[0]) & (data_train.pickup_latitude < ylim[1])]\n    data_train = data_train[(data_train.dropoff_latitude> ylim[0]) & (data_train.dropoff_latitude < ylim[1])]\n\n    return (data_train, data_test)\n\n\ndef train_xgb(X_train, labels):\n    Xtr, Xv, ytr, yv = train_test_split(X_train.values,\n                                        labels,\n                                        test_size=0.2,\n                                        random_state=0)\n\n    dtrain = xgb.DMatrix(Xtr, label=ytr)\n    dvalid = xgb.DMatrix(Xv, label=yv)\n\n    evals = [(dtrain, 'train'), (dvalid, 'valid')]\n\n    params = {\n        'min_child_weight': 1, 'eta': 0.166,\n        'colsample_bytree': 0.4, 'max_depth': 9,\n        'subsample': 1.0, 'lambda': 57.93,\n        'booster': 'gbtree', 'gamma': 0.5,\n        'silent': 1, 'eval_metric': 'rmse',\n        'objective': 'reg:linear',\n    }\n\n    model = xgb.train(params=params, dtrain=dtrain, num_boost_round=227,\n                      evals=evals, early_stopping_rounds=60, maximize=False,\n                      verbose_eval=10)\n\n    print('Modeling RMSLE %.5f' % model.best_score)\n    return model\n\n\ndef predict_xgb(model, X_test):\n    dtest = xgb.DMatrix(X_test.values)\n    ytest = model.predict(dtest)\n    X_test['trip_duration'] = np.exp(ytest) - 1\n    return X_test[['trip_duration']]\n\n\ndef feature_importances(model, feature_names):\n    feature_importance_dict = model.get_fscore()\n    fs = ['f%i' % i for i in range(len(feature_names))]\n    f1 = pd.DataFrame({'f': list(feature_importance_dict.keys()),\n                       'importance': list(feature_importance_dict.values())})\n    f2 = pd.DataFrame({'f': fs, 'feature_name': feature_names})\n    feature_importance = pd.merge(f1, f2, how='right', on='f')\n    feature_importance = feature_importance.fillna(0)\n    return feature_importance[['feature_name', 'importance']].sort_values(by='importance',\n                                                                          ascending=False)\n\n\ndef get_train_test_fm(feature_matrix):\n    X_train = feature_matrix[feature_matrix['test_data'] == False]\n    X_train = X_train.drop(['test_data'], axis=1)\n    labels = X_train['trip_duration']\n    X_train = X_train.drop(['trip_duration'], axis=1)\n    X_test = feature_matrix[feature_matrix['test_data'] == True]\n    X_test = X_test.drop(['test_data', 'trip_duration'], axis=1)\n    return (X_train, labels, X_test)\n\n\ndef duplicate_columns(frame):\n    groups = frame.columns.to_series().groupby(frame.dtypes).groups\n    dups = []\n    for t, v in groups.items():\n        dcols = frame[v].to_dict(orient=\"list\")\n\n        vs = dcols.values()\n        ks = dcols.keys()\n        lvs = len(vs)\n\n        for i in range(lvs):\n            for j in range(i+1,lvs):\n                if vs[i] == vs[j]:\n                    dups.append(ks[i])\n                    break\n    return dups","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hypothesis function\ndef hyp(theta, X):\n    return np.dot(X, theta.T)  \n\n# The loss function in our case is the sum of the squared error\ndef loss_func(theta, X, Y):\n    return np.sum(((hyp(theta, X) - Y)**2) / (2 * X.shape[0]))\n\ndef get_gradient(theta, X, Y):\n    derivatives = []\n  \n    for i in range(0, X.shape[1]):\n        derivatives.append(np.sum((hyp(theta, X) - Y) * X[:, i]) / X.shape[0])\n\n    return np.array(derivatives)\n\ndef gradient_descent(X, Y, maxniter=20000):\n    thetas = np.random.rand(X.shape[1],)\n    alpha = 0.001\n    costs = []\n    \n    for i in range(0, maxniter):\n        thetas = thetas - (alpha * get_gradient(thetas, X, Y))\n        costs.append(loss_func(thetas, X, Y))\n        \n    return thetas, costs","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"proc_data = process_data(train_data)\n# proc_data = proc_data[(proc_data['trip_duration'] >= 120) & (proc_data['trip_duration'] <= 3000)]\n# proc_data = proc_data[proc_data.trip_duration <= np.percentile(proc_data.trip_duration, 99)]\n# proc_data = proc_data[proc_data.dist <= np.percentile(proc_data.dist, 98)]\nX = proc_data.drop('trip_duration', axis=1).values\nY = proc_data['trip_duration'].values\n\nmax_iters = 5000\nthetas, costs = gradient_descent(X, Y, max_iters)\nplt.ylabel('Loss')\nplt.xlabel('Iterations')\nplt.plot(np.arange(0, max_iters), costs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = hyp(thetas, process_data(test_data))\n\nsubmission = pd.DataFrame({'id':test_data['id'],'trip_duration':pred})\nsubmission.to_csv(\"submission.csv\", index=False)\n\nprint(pd.DataFrame(pred).describe())\nprint(submission)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"count  30000.000000\nmean     951.616440\nstd      551.389681\nmin      266.693274\n25%      634.700283\n50%      808.378487\n75%     1046.484861\nmax     8028.482600"},{"metadata":{"trusted":true},"cell_type":"code","source":"proc_data = process_data(train_data)\ntest_proc = process_data(test_data)\n\nX = proc_data.drop('trip_duration', axis=1)\nY = proc_data['trip_duration']\n\ndata_dmatrix = xgb.DMatrix(data=X,label=Y)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\nxg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 5, alpha = 10, n_estimators = 10)\n\nxg_reg.fit(X_train,y_train)\npreds = xg_reg.predict(X_test)","execution_count":13,"outputs":[{"output_type":"stream","text":"[0]\ttrain-rmse:3508.39\tvalid-rmse:3055.37\nMultiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n\nWill train until valid-rmse hasn't improved in 60 rounds.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n  if getattr(data, 'base', None) is not None and \\\n","name":"stderr"},{"output_type":"stream","text":"[10]\ttrain-rmse:3344.62\tvalid-rmse:2933.2\n[20]\ttrain-rmse:3280.89\tvalid-rmse:2916.75\n[30]\ttrain-rmse:3225.79\tvalid-rmse:2914.91\n[40]\ttrain-rmse:3174.83\tvalid-rmse:2918.55\n[50]\ttrain-rmse:3135.28\tvalid-rmse:2922.11\n[60]\ttrain-rmse:3093.09\tvalid-rmse:2926.71\n[70]\ttrain-rmse:3043.22\tvalid-rmse:2933.08\n[80]\ttrain-rmse:3002.59\tvalid-rmse:2941.37\nStopping. Best iteration:\n[27]\ttrain-rmse:3245.31\tvalid-rmse:2914.5\n\nModeling RMSLE 2914.50024\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:57: RuntimeWarning: overflow encountered in exp\n","name":"stderr"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"   trip_duration\n0            inf\n1            inf\n2            inf\n3            inf\n4            inf","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trip_duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>inf</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>inf</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>inf</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>inf</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>inf</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing outliers\n\n# 1-\n# temp = train_data[train_data.trip_duration <= np.percentile(train_data.trip_duration, 99)]\n\n# 2-\n# temp = process_data(train_data)\n# temp = temp[(temp['trip_duration'] >= 120) & (temp['trip_duration'] <= 3000)]\n# temp = temp[(temp['dist'] > 0)]\n# temp = temp[temp.dist <= np.percentile(temp.dist, 98)]\n\n# print(temp.passenger_count.describe())\n\n# print(temp.trip_duration.describe())\n\n# fig, ax = plt.subplots()\n# sns.distplot(temp['trip_duration'], hist=False, rug=True)\n# sns.distplot(temp['dist'], hist=False, rug=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}